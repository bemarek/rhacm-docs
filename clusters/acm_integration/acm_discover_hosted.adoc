[#discovering-hcp-acm]
= Discovering {mce-short} hosted clusters in {product-title-short}

If you have {mce-short} clusters that are hosting many hosted clusters, you can bring these hosted clusters to a {product-title-short} hub cluster to manage with {product-title-short} management components, such as _Application lifecycle_ and _Governance_.

You can have those hosted clusters automatically discovered and imported as managed clusters.

Since the hosted control planes run on the managed {mce-short} cluster nodes, the number of hosted control planes the cluster can host is determined by the resource availability of managed {mce-short} cluster nodes, as well as the number of managed {mce-short} clusters. 

You can add more nodes or managed clusters to host more hosted control planes.

*Required access:* Cluster administrator

* <<-manage-discover-prereqs,Prerequisites>>
* Configuring {product-title-short} to import {mce-short} clusters
* Importing {mce-short} 
* Discovering hosted clusters from MCE
* This requires `oc` and `clusteradm` CLIs.
//find this link

[#manage-discover-prereqs]
== Prerequisites

* You need one or more {mce-short} hosting clusters that are _managed_ clusters. These clusters are not {ocp} or {product-title-short} clusters because {mce-short} installs other operators, such as Hive and BareMetal infrastructure operators that you need.

* You need a {product-title-short} cluster as your hub cluster.

[#manage-discover-scale]
== Configuring {product-title-short} to import {mce-short} clusters
//check this order of tasks if we break out this in to two files: Disover/Manage and Auto import

{mce-short} has a `local-cluster`, which is a hub cluster that is managed. The default add-ons are enabled for this `local-cluster`.


//what are we asking them to do here? Double check my work:

. Run the following command to get the `managedclusteradd-ons` status for your `local-cluster`:

+
[source,bash]
----
oc get managedclusteradd-ons -n local-cluster
----

See the example output:

+
[source,bash]
----
NAME                     AVAILABLE   DEGRADED   PROGRESSING
cluster-proxy            True                   False
hypershift-add-ons         True        False      False
managed-serviceaccount   True                   False
work-manager             True                   False
----

. Run the following command to 
//what are they doing here?

+
[source,bash]
----
oc get deployment -n open-cluster-management-agent-add-ons
----

See the following output...:
//what are they looking for here?

+
[source,bash]
----
NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE
cluster-proxy-proxy-agent            1/1     1            1           25h
hypershift-add-ons-agent               1/1     1            1           25h
klusterlet-add-ons-workmgr             1/1     1            1           25h
managed-serviceaccount-add-ons-agent   1/1     1            1           25h
----

[#install-add-onss-mce]
=== Configuring add-ons 
// Check the order here of the tasks, has import happened?

When this {mce-short} is imported into {product-title-short}, {product-title-short} enables the same set of add-ons to manage the {mce-short}. 

Install those add-ons in a different namespace in {mce-short} so that {mce-short} can still self-manage with the `local-cluster` add-ons while {mce-short} can be managed by {product-title-short} at the same time.

. Log in to your {product-title-short} with the CLI.
//hub cluster? 

. Create the `add-onsDeploymentConfig` resource to specify a different add-on installation namespace. See the following example where `agentInstallNamespace` points to `open-cluster-management-agent-add-ons-discovery`:
//check what we want to highlight here?

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: add-onsDeploymentConfig
metadata:
  name: add-ons-ns-config
  namespace: multicluster-engine
spec:
  agentInstallNamespace: open-cluster-management-agent-add-ons-discovery
----

. Update the existing `ClusterManagementadd-ons` resources for these add-ons so that the add-ons have the `agentInstallNamespace` namespace that you created in the  `add-onsDeploymentConfig` resource.

See the following `ClusterManagementadd-ons` example resource for the `work-manager` add-on:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: ClusterManagementadd-ons
metadata:
  name: work-manager
spec:
  add-onsMeta:
    displayName: work-manager
  installStrategy:
    placements:
    - name: global
      namespace: open-cluster-management-global-set
      rolloutStrategy:
        type: All
    type: Placements
----

. Add the `add-onsDeploymentConfig` to the `ClusterManagementadd-ons`. See the following example:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: ClusterManagementadd-ons
metadata:
  name: work-manager
spec:
  add-onsMeta:
    displayName: work-manager
  installStrategy:
    placements:
    - name: global
      namespace: open-cluster-management-global-set
      rolloutStrategy:
        type: All
      configs:
      - group: add-ons.open-cluster-management.io
        name: add-ons-ns-config
        namespace: multicluster-engine
        resource: add-onsdeploymentconfigs
    type: Placements
----

. Add the `add-onsDeploymentConfig` to the `managed-serviceaccount`. See the following example:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: ClusterManagementadd-ons
metadata:
  name: managed-serviceaccount
spec:
  add-onsMeta:
    displayName: managed-serviceaccount
  installStrategy:
    placements:
    - name: global
      namespace: open-cluster-management-global-set
      rolloutStrategy:
        type: All
      configs:
      - group: add-ons.open-cluster-management.io
        name: add-ons-ns-config
        namespace: multicluster-engine
        resource: add-onsdeploymentconfigs
    type: Placements
----

. Add the `add-onsDeploymentConfig` to the `cluster-proxy` add-ons. See the following example:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: ClusterManagementadd-ons
metadata:
  name: cluster-proxy
spec:
  add-onsMeta:
    displayName: cluster-proxy
  installStrategy:
    placements:
    - name: global
      namespace: open-cluster-management-global-set
      rolloutStrategy:
        type: All
      configs:
      - group: add-ons.open-cluster-management.io
        name: add-ons-ns-config
        namespace: multicluster-engine
        resource: add-onsdeploymentconfigs
    type: Placements
----

The add-ons for the {product-title-short} `local-cluster` and all other managed clusters are re-installed into the namespace that you specified. 

+
[source,bash]
----
oc get deployment -n open-cluster-management-agent-add-ons-discovery
----

. See the following output:

+
[source,bash]
----
NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE
cluster-proxy-proxy-agent            1/1     1            1           24h
klusterlet-add-ons-workmgr             1/1     1            1           24h
managed-serviceaccount-add-ons-agent   1/1     1            1           24h
----

[#create-klusterletconfig]
=== Creating a _KlusterletConfig_ resource

You need to create a `KlusterletConfig` resource that is used by `ManagedCluster` resources to import {mce-short} clusters. 

When a `ManagedCluster` references this `KlusterletConfig` resource, the managed cluster klusterlet is installed in the namespace that you specified in the `KlusterletConfig`. 

You can import the {product-title-short} klusterlet to be installed in a different namespace than the {mce-short} klusterlet for the self-managed `local-cluster`` managed cluster in the {mce-short} cluster.
//fix this--this is a bit hard to understand, and use steps to lead to the YAML:

+
[source,yaml]
----
kind: KlusterletConfig
apiVersion: config.open-cluster-management.io/v1alpha1
metadata:
  name: mce-import-klusterlet-config
spec:
  installMode:
    type: noOperator
    noOperator:
       postfix: mce-import
----

[#backup-restore-discover]
=== Configure for backup and restore

Since you have {product-title-short} installed, you can use the _Backup and restore_ feature.

If the hub cluster is restored in a disaster recovery scenario, the imported {mce-short} clusters and the hosted clusters are imported to the newer {product-title-short} hub cluster. 

The previous configurations need to be restored as part of {product-title-short} hub cluster restore. 

Add `backup=true`  to those resources to enable backup. See the following commands:

. For your `add-ons-ns-config`, run the following command:

+
[source,bash]
----
oc label add-onsdeploymentconfig add-ons-ns-config -n multicluster-engine cluster.open-cluster-management.io/backup=true
----

. For your `hypershift-add-ons-deploy-config`, run the following command:

+
[source,bash]
----
oc label add-onsdeploymentconfig hypershift-add-ons-deploy-config -n multicluster-engine cluster.open-cluster-management.io/backup=true
----

. For your `work-manager`, run the following command:

+
[source,bash]
----
oc label clustermanagementadd-ons work-manager cluster.open-cluster-management.io/backup=true
----

. For your `cluster-proxy `, run the following command:

+
[source,bash]
----
oc label clustermanagementadd-ons cluster-proxy cluster.open-cluster-management.io/backup=true
----

. For your `managed-serviceaccount`, run the following command:
+
[source,bash]
----
oc label clustermanagementadd-ons managed-serviceaccount cluster.open-cluster-management.io/backup=true
----

. For your `mce-import-klusterlet-config`, run the following command:

+
[source,bash]
----
oc label KlusterletConfig mce-import-klusterlet-config cluster.open-cluster-management.io/backup=true
----

[#import]
== Importing {mce-short} 

. From your {product-title-short} cluster, create a `ManagedCluster` resource manually to import an {mce-short} cluster. See the following resource to import an {mce-short} managed cluster named `mce-a`.

+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  annotations:
    agent.open-cluster-management.io/klusterlet-config: mce-import-klusterlet-config
  name: mce-a
spec:
  hubAcceptsClient: true
  leaseDurationSeconds: 60
----

*Note:* See the  `agent.open-cluster-management.io/klusterlet-config: mce-import-klusterlet-config` annotation that references the `KlusterletConfig` resource that you created in the previous step to install the {product-title-short} klusterlet into a different namespace in {mce-short}.
//this is a mouthful

The managed cluster and the namespace is created in the {product-title-short} cluster. 
//verify: Roke will add more steps.

. Add the auto import secret. Follow https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.10/html-single/clusters/index#importing-clusters-auto-import-secret to create the auto-import secret to complete the {mce-short} auto-import process. 

After the auto import secret is created in the {mce-short} managed cluster namespace in the {product-title-short} cluster, the managed cluster gets registered and you should see the managed cluster status:

+
[source,bash]
----
oc get managedcluster
----

See following output with the status of managed clusters:
+
[source,bash]
----
NAME            HUB ACCEPTED   MANAGED CLUSTER URLS                                         JOINED   AVAILABLE   AGE
local-cluster   true           https://api.acm-hub-hs-aws.dev09.red-chesterfield.com:6443   True     True        44h
mce-a           true           https://api.clc-hs-mce-a.dev09.red-chesterfield.com:6443     True     True        27s
----

*Important:* Do not enable any other {product-title-short} add-ons for the imported {mce-short}.

== Discovering hosted clusters

After all {mce-short} clusters are imported into {product-title-short}, you need to enable the hypershift add-on for those managed {mce-short} clusters to discover the hosted clusters.

in the {product-title-short} hub cluster to enable the hypershift add-on. Similar to how the default add-ons are intalled into a different namespace in the previous section, these commands are for installing the hypershift add-ons into a different namespace in {mce-short} as well so that the hypershift add-ons agent for {mce-short}'s local-cluster and the agent for {product-title-short} can co-exist in {mce-short}. 

. Run the following commands to set the `agentInstallNamespace` namespace of the add-on to `open-cluster-management-agent-add-ons-discovery`:
----
oc patch add-onsdeploymentconfig hypershift-add-ons-deploy-config -n multicluster-engine --type=merge -p '{"spec":{"agentInstallNamespace":"open-cluster-management-agent-add-ons-discovery"}}'
----

. Run the following commands to disable metrics and to disable the hypershift operator management:

----
oc patch add-onsdeploymentconfig hypershift-add-ons-deploy-config -n multicluster-engine --type=merge -p '{"spec":{"customizedVariables":[{"name":"disableMetrics","value": "true"},{"name":"disableHOManagement","value": "true"}]}}'
----
. Run the following commands to enable the hypershift add-on for {mce-short}:

----
clusteradm add-ons enable --names hypershift-addon --clusters <managed cluster names>
----

Replace <managed cluster names> with the actual managed cluster names for {mce-short}, comma separated. 

. You can get the {mce-short} managed cluster names by running the following command in {product-title-short}.

----
oc get managedcluster
----

. Log into {mce-short} clusters and verify that the hypershift add-on is installed in the specified namespace. Run the following command:

----
oc get deployment -n open-cluster-management-agent-add-ons-discovery
----

----
NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE
klusterlet-add-ons-workmgr             1/1     1            1           24h
hypershift-add-ons-agent               1/1     1            1           24h
managed-serviceaccount-add-ons-agent   1/1     1            1           24h
----

This hypershift add-on is deployed by {product-title-short} acts as a discovery agent that discovers hosted clusters from {mce-short} and create corresponding `DiscoveredCluster` CR in the {mce-short}'s managed cluster namespace in the {product-title-short} hub cluster when the hosted cluster's kube API server becomes available. 
<<<<<<< HEAD

Log into {product-title-short} hub console, navigate to *All Clusters* > *Infrastructure* > *Clusters*. Find the _Discovered clusters_ tab to view all discovered hosted clusters from {mce-short} with type `MultiClusterEngineHCP`. 


Next go to the HCP Import

New File:

Next go to the HCP Import
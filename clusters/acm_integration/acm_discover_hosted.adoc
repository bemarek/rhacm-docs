[#discovering-hcp-acm]
= Discovering {mce-short} hosted clusters in {product-title-short}

If you have {mce-short} clusters that are hosting multiple _hosted clusters_, you can bring those hosted clusters to a {product-title-short} hub cluster to manage with {product-title-short} management components, such as _Application lifecycle_ and _Governance_.

You can have those hosted clusters automatically discovered and imported as managed clusters.

*Note:* Since the hosted control planes run on the managed {mce-short} cluster nodes, the number of hosted control planes that the cluster can host is determined by the resource availability of managed {mce-short} cluster nodes, as well as the number of managed {mce-short} clusters.You can add more nodes or managed clusters to host more hosted control planes.

*Required access:* Cluster administrator

* <<discover-prereqs, Prerequisites>>
* <<config-acm-import, Configuring {product-title-short} to import {mce-short} clusters>>
* <<import-mce-manually,Importing {mce-short} manually>>
* <<discover-hosted-acm-mce, Discovering hosted clusters from {mce-short}>>

[#discover-hosted-acm-prereqs]
== Prerequisites

* You need one or more {mce-short} hosting clusters that are _managed_ clusters. These clusters are not {ocp} or {product-title-short} clusters because {mce-short} installs other operators, such as Hive and BareMetal infrastructure operators that you need.

* You need a {product-title-short} cluster set as your hub cluster.

* You need the `clusteradm` CLI in addition to `oc`.

[#config-acm-import-hosted]
== Configuring {product-title-short} to import hosted clusters

{mce-short} has a `local-cluster`, which is a hub cluster that is managed. The default add-ons are enabled for this `local-cluster`. Complete the following procedure to configure your local cluster to import:

. Run the following command to get the list of `managedclusteradd-ons` for your `local-cluster`:

+
[source,bash]
----
oc get managedclusteradd-ons -n local-cluster
----

See the example output of available add-ons:

+
[source,bash]
----
NAME                     AVAILABLE   DEGRADED   PROGRESSING
cluster-proxy            True                   False
hypershift-add-ons       True        False      False
managed-serviceaccount   True                   False
work-manager             True                   False
----

. Run the following command to get your add-ons:
//what are they doing here?

+
[source,bash]
----
oc get deployment -n open-cluster-management-agent-add-ons
----

See the following output:
//what are they looking for here?
+
[source,bash]
----
NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE
cluster-proxy-proxy-agent              1/1     1            1         25h
hypershift-add-ons-agent               1/1     1            1         25h
klusterlet-add-ons-workmgr             1/1     1            1         25h
managed-serviceaccount-add-ons-agent   1/1     1            1         25h
----

[#config-add-ons-mce]
=== Configuring add-ons 

When your {mce-short} is imported into {product-title-short}, {product-title-short} enables the same set of add-ons to manage the {mce-short}. 

Install those add-ons in a different {mce-short} namespace so that the {mce-short} can self-manage with the `local-cluster` add-ons while  {product-title-short} manages {mce-short} at the same time. Complete the following procedure:

. Log in to your {product-title-short} with the CLI.

. Create the addonsDeploymentConfig` resource to specify a different add-on installation namespace. See the following example where `agentInstallNamespace` points to `open-cluster-management-agent-add-ons-discovery`:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: add-onsDeploymentConfig
metadata:
  name: add-ons-ns-config
  namespace: multicluster-engine
spec:
  agentInstallNamespace: open-cluster-management-agent-add-ons-discovery
----

. Update the existing `ClusterManagementadd-ons` resources for the add-ons so that the addonsDeploymentConfig` resource have the `agentInstallNamespace` namespace that you created.
//is this the highlevel step and adding work manager is part 1? this is simlar to the step after it.
See the following `ClusterManagementadd-ons` example resource for the `work-manager` add-on:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: ClusterManagementadd-ons
metadata:
  name: work-manager
spec:
  add-onsMeta:
    displayName: work-manager
  installStrategy:
    placements:
    - name: global
      namespace: open-cluster-management-global-set
      rolloutStrategy:
        type: All
    type: Placements
----

. Add the `addonsDeploymentConfig` to the `ClusterManagementadd-ons`. See the following example:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: ClusterManagementadd-ons
metadata:
  name: work-manager
spec:
  add-onsMeta:
    displayName: work-manager
  installStrategy:
    placements:
    - name: global
      namespace: open-cluster-management-global-set
      rolloutStrategy:
        type: All
      configs:
      - group: add-ons.open-cluster-management.io
        name: add-ons-ns-config
        namespace: multicluster-engine
        resource: add-onsdeploymentconfigs
    type: Placements
----

. Add the `addonsDeploymentConfig` to the `managed-serviceaccount`. See the following example:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: ClusterManagementadd-ons
metadata:
  name: managed-serviceaccount
spec:
  add-onsMeta:
    displayName: managed-serviceaccount
  installStrategy:
    placements:
    - name: global
      namespace: open-cluster-management-global-set
      rolloutStrategy:
        type: All
      configs:
      - group: add-ons.open-cluster-management.io
        name: add-ons-ns-config
        namespace: multicluster-engine
        resource: add-onsdeploymentconfigs
    type: Placements
----

. Add the `addonsDeploymentConfig` to the `cluster-proxy` add-ons. See the following example:

+
[source,yaml]
----
apiVersion: add-ons.open-cluster-management.io/v1alpha1
kind: ClusterManagementadd-ons
metadata:
  name: cluster-proxy
spec:
  add-onsMeta:
    displayName: cluster-proxy
  installStrategy:
    placements:
    - name: global
      namespace: open-cluster-management-global-set
      rolloutStrategy:
        type: All
      configs:
      - group: add-ons.open-cluster-management.io
        name: add-ons-ns-config
        namespace: multicluster-engine
        resource: add-onsdeploymentconfigs
    type: Placements
----

The add-ons for the {product-title-short} `local-cluster` and all other managed clusters are re-installed into the namespace that you specified. 

Run the following command to verify:
//??

+
[source,bash]
----
oc get deployment -n open-cluster-management-agent-add-ons-discovery
----

. See the following output:

+
[source,bash]
----
NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE
cluster-proxy-proxy-agent            1/1     1            1           24h
klusterlet-add-ons-workmgr             1/1     1            1           24h
managed-serviceaccount-add-ons-agent   1/1     1            1           24h
----

[#create-klusterletconfig]
=== Creating a _KlusterletConfig_ resource

When a `ManagedCluster` references the `KlusterletConfig` resource, the managed cluster `klusterlet` is installed in the namespace that you specified in the `KlusterletConfig`. 

Create a `KlusterletConfig` resource that is used by `ManagedCluster` resources to import {mce-short} clusters. 

You can import the {product-title-short} klusterlet to be installed in a different namespace than the {mce-short} klusterlet for the `local-cluster` in the {mce-short} cluster.
//still struggling with this

. Create a `KlusterletConfig` using the following example:
//?
+
[source,yaml]
----
kind: KlusterletConfig
apiVersion: config.open-cluster-management.io/v1alpha1
metadata:
  name: mce-import-klusterlet-config
spec:
  installMode:
    type: noOperator
    noOperator:
       postfix: mce-import
----

[#backup-restore-discover]
=== Configure for backup and restore

Since you installed {product-title-short} , you can also use the _Backup and restore_ feature.

If the hub cluster is restored in a disaster recovery scenario, the imported {mce-short} clusters and hosted clusters are imported to the newer {product-title-short} hub cluster. 

In this scenario, you need to restore the previous configurations as part of {product-title-short} hub cluster restore. 

Add `backup=true` to enable backup. See the following steps for each add-on:

* For your addons-ns-config`, run the following command:

+
[source,bash]
----
oc label add-onsdeploymentconfig add-ons-ns-config -n multicluster-engine cluster.open-cluster-management.io/backup=true
----

* For your `hypershift-add-ons-deploy-config`, run the following command:

+
[source,bash]
----
oc label add-onsdeploymentconfig hypershift-add-ons-deploy-config -n multicluster-engine cluster.open-cluster-management.io/backup=true
----

* For your `work-manager`, run the following command:

+
[source,bash]
----
oc label clustermanagementadd-ons work-manager cluster.open-cluster-management.io/backup=true
----

* For your `cluster-proxy `, run the following command:

+
[source,bash]
----
oc label clustermanagementadd-ons cluster-proxy cluster.open-cluster-management.io/backup=true
----

* For your `managed-serviceaccount`, run the following command:

+
[source,bash]
----
oc label clustermanagementadd-ons managed-serviceaccount cluster.open-cluster-management.io/backup=true
----

* For your `mce-import-klusterlet-config`, run the following command:

+
[source,bash]
----
oc label KlusterletConfig mce-import-klusterlet-config cluster.open-cluster-management.io/backup=true
----

[#import]
== Importing {mce-short} manually

. From your {product-title-short} cluster, create a `ManagedCluster` resource manually to import an {mce-short} cluster. 

+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  annotations:
    agent.open-cluster-management.io/klusterlet-config: mce-import-klusterlet-config <1>
  name: mce-a <2>
spec:
  hubAcceptsClient: true
  leaseDurationSeconds: 60
----

<1> The `mce-import-klusterlet-config` annotation references the `KlusterletConfig` resource that you created in the previous step to install the {product-title-short} klusterlet into a different namespace in {mce-short}.
<2> The example imports an {mce-short} managed cluster named `mce-a`.

The managed cluster and the namespace is created in the {product-title-short} cluster. 
//verify?
. Create a secret that references the `kubeconfig`` file of the cluster. Go to xref:../cluster_lifecycle/import_cli.adoc#importing-clusters-auto-import-secret [Importing a cluster by using the auto import secret] to add the auto import secret to complete the {mce-short} auto-import process. 

After you create the auto import secret in the {mce-short} managed cluster namespace in the {product-title-short} cluster, the managed cluster is registered.

. Run the following command to get the status:

+
[source,bash]
----
oc get managedcluster
----

See following example output with the status and example urls of managed clusters:

+
[source,bash]
----
NAME           HUB ACCEPTED   MANAGED CLUSTER URLS            JOINED   AVAILABLE   AGE
local-cluster  true           https://<api.acm-hub.com:port>  True     True        44h
mce-a          true           https://<api.mce-a.com:port>    True     True        27s
----

*Important:* Do not enable any other {product-title-short} add-ons for the imported {mce-short}.

[discover-hosted-clusters]
== Discovering hosted clusters

After all your {mce-short} clusters are imported into {product-title-short}, you need to enable the hypershift add-on for those managed {mce-short} clusters to discover the hosted clusters.

Default add-ons are installed in to a different namespace in the previous procedures. Similarly, you install the `hypershift-add-ons` in to a different namespace in {mce-short} so that the add-ons agent for {mce-short} local-cluster and the agent for {product-title-short} can work in {mce-short}. 

*Important:* For all the following commands, replace `<managed-cluster-names>` with comma-separated managed cluster names for {mce-short}.

. Run the following command to set the `agentInstallNamespace` namespace of the add-on to `open-cluster-management-agent-add-ons-discovery`:

+
[source,bash]
----
oc patch add-onsdeploymentconfig hypershift-add-ons-deploy-config -n multicluster-engine --type=merge -p '{"spec":{"agentInstallNamespace":"open-cluster-management-agent-add-ons-discovery"}}'
----

. Run the following command to disable metrics and to disable the hypershift operator management:

+
[source,bash]
----
oc patch add-onsdeploymentconfig hypershift-add-ons-deploy-config -n multicluster-engine --type=merge -p '{"spec":{"customizedVariables":[{"name":"disableMetrics","value": "true"},{"name":"disableHOManagement","value": "true"}]}}'
----

. Run the following command to enable the `hypershift-addon` for {mce-short}:

+
[source,bash]
----
clusteradm add-ons enable --names hypershift-addon --clusters <managed-cluster-names>
----

. You can get the {mce-short} managed cluster names by running the following command in {product-title-short}.

+
[source,bash]
----
oc get managedcluster
----

. Log into {mce-short} clusters and verify that the hypershift add-on is installed in the namespace that you specified. Run the following command:

+
[source,bash]
----
oc get deployment -n open-cluster-management-agent-add-ons-discovery
----
 
See the following example output that lists the add-ons:

+
[source,bash]
----
----
NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE
klusterlet-add-ons-workmgr           1/1     1            1           24h
hypershift-add-ons-agent             1/1     1            1           24h
managed-serviceaccount-add-ons-agent 1/1     1            1           24h
----

{product-title-short} deploys the `hypershift-add-on`, which is the discovery agent that discovers hosted clusters from {mce-short}. The agent creates the corresponding `DiscoveredCluster` custom resource in the {mce-short} managed cluster namespace in the {product-title-short} hub cluster when the hosted cluster kube API server becomes available. 

. Log into hub cluster console and navigate to *All Clusters* > *Infrastructure* > *Clusters*. 
. Find the _Discovered clusters_ tab to view all discovered hosted clusters from {mce-short} with type `MultiClusterEngineHCP`. 

Now you can go to [Automating import for discovered hosted clusters].
//will link here
